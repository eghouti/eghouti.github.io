# Important Dates

- Paper submission deadline: 26 February 2021.
- Acceptance notification: 26 March 2021.

# Author Instructions

The authors have to follow the instructions listed below when submitting thier contributions:

- Use the ICLR LaTeX [template](https://github.com/ICLR/Master-Template/raw/master/archive/iclr2021.zip) to prepare the manuscript.
- Papers should not be longer than 4 pages, including figures and tables, and excluding references.
- Do not report author names since the review is double blind.
- Published work in the main ICLR conference are not accepted for a submition into the workshop. Papers that violate this rule will be rejected.  
- Manuscripts should be submitted using the CMT system. 

# Scope and Topics

The workshop welcomes contributions that seek to reduce the cost of the training process by taking into account the details of the computing hardware (CPU, GPU, IPU, NPU, or any other custom accelerator implemented as an ASIC or on FPGA) including (but not limited to):

- compression methods to reduce memory usage and/or complexity of deep learning during training,
- hardware architectures and implementations for deep learning training,
- energy reduction techniques for deep learning training,
- open-source designs, implementations and code related to efficient deep-learning implementations,
- energy models or energy-efficiency benchmarks for deep learning training implementations,
- applications of low-energy deep learning training,
- equilibrium-propagation-based techniques and/or their hardware implementations,
- few-shot/few-labels and semi-supervised learning methods for training on chip. 
